{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch on TPU, GPU",
      "provenance": [],
      "collapsed_sections": [
        "f8xe19rFjz8P",
        "lhOeVK6RKz1-",
        "EM7EnBoyK8nR"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thetinybug/MLDL-LearnPyTorch/blob/master/Pytorch_on_TPU%2C_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMKCryQnh9UV",
        "colab_type": "text"
      },
      "source": [
        "#Choose Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrnLhnrJhpAh",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "use_gpu = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6rMgNXdh8yd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3ce6a14-d304-4008-9611-8dfa68af6c18"
      },
      "source": [
        "import os\n",
        "tpu_existed = True\n",
        "\n",
        "try:\n",
        "    assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "    print(\"TPU Ready!\")\n",
        "except KeyError:\n",
        "    print(\"Not Exist TPU!\")\n",
        "    tpu_existed = False"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not Exist TPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUdrKNcTHaqe",
        "colab_type": "text"
      },
      "source": [
        "# Install PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-LqHiVsHGrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f174635f-ba40-4d87-88e9-36b5e5412c76"
      },
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: torch==1.5.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.5.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchvision) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vftiv2zbi-uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_tpu and tpu_existed:\n",
        "    VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "    !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxgCzP8pHqYL",
        "colab_type": "text"
      },
      "source": [
        "# Import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqgh6bI9HgiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "if use_tpu and tpu_existed:\n",
        "    # imports the torch_xla package\n",
        "    import torch_xla\n",
        "    import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgFsm9fPHv-W",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YeEfyh5Hpq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size    = 784   # The image size = 28 x 28 = 784\n",
        "hidden_size   = 500   # The number of nodes at the hidden layer\n",
        "num_classes   = 10    # The number of output classes. In this case, from 0 to 9\n",
        "num_epochs    = 5     # The number of times entire dataset is trained\n",
        "batch_size    = 100   # The size of input data took for one iteration\n",
        "learning_rate = 1e-3  # The speed of convergence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsLqpXjxILFn",
        "colab_type": "text"
      },
      "source": [
        "# Download MNIST Dataset\n",
        "\n",
        "MNIST is a huge database of handwritten digits (i.e. 0 to 9) that is often used in image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRuFHe7GIDdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                           train=True,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hgCecJDIi8o",
        "colab_type": "text"
      },
      "source": [
        "# Build the Feedforward Neural Network\n",
        "\n",
        "### Feedforward Neural Network Model Structure\n",
        "\n",
        "The FNN includes two fully-connected layers (i.e. fc1 & fc2) and a non-linear ReLU layer in between. Normally we call this structure **1-hidden layer FNN**, without counting the output layer (fc2) in.\n",
        "\n",
        "By running the forward pass, the input images (x) can go through the neural network and generate a output (out) demonstrating how are the likabilities it belongs to each of the 10 classes. _For example, a cat image can have 0.8 likability to a dog class and a 0.3 likability to a airplane class._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rnAhgUlIr5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
        "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
        "    \n",
        "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qgBYVkxIxym",
        "colab_type": "text"
      },
      "source": [
        "# Instantiate the FNN\n",
        "\n",
        "We now create a real FNN based on our structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvLScxMxI0_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net(input_size, hidden_size, num_classes)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5pOMFEPJEtd",
        "colab_type": "text"
      },
      "source": [
        "# Choose the Loss Function and Optimizer\n",
        "\n",
        "Loss function (**criterion**) decides how the output can be compared to a class, which determines how good or bad the neural network performs. And the **optimizer** chooses a way to update the weight in order to converge to find the best weights in this neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo60XGznI_Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# net = Net(input_size, hidden_size, num_classes)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLUaX6tuJMQi",
        "colab_type": "text"
      },
      "source": [
        "# Training the FNN Model\n",
        "\n",
        "This process might take around 3 to 5 minutes depending on your machine. The detailed explanations are listed as comments (#) in the following codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBrGa7qMJKcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "b742fd9f-d42f-46be-cbc3-99802fcdbd24"
      },
      "source": [
        "import timeit\n",
        "print(100*'=')\n",
        "net = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "if use_tpu and tpu_existed:\n",
        "    dev = xm.xla_device()\n",
        "    # print(\" Device created!\")\n",
        "    net = net.to(dev)\n",
        "    print(\"Use TPU\")\n",
        "elif use_gpu and torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "    print(\"Use GPU\")\n",
        "else:\n",
        "    print(\"Use CPU\")\n",
        "print(100*'-')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = timeit.default_timer()\n",
        "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
        "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        if use_tpu and tpu_existed:\n",
        "            images = images.to(dev)\n",
        "            labels = labels.to(dev)\n",
        "        elif use_gpu and torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data))\n",
        "    runtime = timeit.default_timer() - start\n",
        "    print(\"Epoch Runtime: \", runtime)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Use TPU\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [1/5], Step [100/600], Loss: 2.3074\n",
            "Epoch [1/5], Step [200/600], Loss: 2.3331\n",
            "Epoch [1/5], Step [300/600], Loss: 2.3297\n",
            "Epoch [1/5], Step [400/600], Loss: 2.3268\n",
            "Epoch [1/5], Step [500/600], Loss: 2.3279\n",
            "Epoch [1/5], Step [600/600], Loss: 2.3343\n",
            "Epoch Runtime:  9.8889253440002\n",
            "Epoch [2/5], Step [100/600], Loss: 2.3344\n",
            "Epoch [2/5], Step [200/600], Loss: 2.3308\n",
            "Epoch [2/5], Step [300/600], Loss: 2.3271\n",
            "Epoch [2/5], Step [400/600], Loss: 2.3350\n",
            "Epoch [2/5], Step [500/600], Loss: 2.3412\n",
            "Epoch [2/5], Step [600/600], Loss: 2.3176\n",
            "Epoch Runtime:  9.288507456999923\n",
            "Epoch [3/5], Step [100/600], Loss: 2.3168\n",
            "Epoch [3/5], Step [200/600], Loss: 2.3304\n",
            "Epoch [3/5], Step [300/600], Loss: 2.3135\n",
            "Epoch [3/5], Step [400/600], Loss: 2.3418\n",
            "Epoch [3/5], Step [500/600], Loss: 2.3128\n",
            "Epoch [3/5], Step [600/600], Loss: 2.3252\n",
            "Epoch Runtime:  9.270580026000061\n",
            "Epoch [4/5], Step [100/600], Loss: 2.3177\n",
            "Epoch [4/5], Step [200/600], Loss: 2.3259\n",
            "Epoch [4/5], Step [300/600], Loss: 2.3288\n",
            "Epoch [4/5], Step [400/600], Loss: 2.3233\n",
            "Epoch [4/5], Step [500/600], Loss: 2.3209\n",
            "Epoch [4/5], Step [600/600], Loss: 2.2977\n",
            "Epoch Runtime:  9.392036717000337\n",
            "Epoch [5/5], Step [100/600], Loss: 2.3300\n",
            "Epoch [5/5], Step [200/600], Loss: 2.3140\n",
            "Epoch [5/5], Step [300/600], Loss: 2.3220\n",
            "Epoch [5/5], Step [400/600], Loss: 2.3219\n",
            "Epoch [5/5], Step [500/600], Loss: 2.3143\n",
            "Epoch [5/5], Step [600/600], Loss: 2.3275\n",
            "Epoch Runtime:  9.28376708399992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b49dSnRmm86z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "026e22e6-395d-4516-ed9c-0b5f6e21c444"
      },
      "source": [
        "import timeit\n",
        "print(100*'=')\n",
        "net = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "# if use_tpu and tpu_existed:\n",
        "#     dev = xm.xla_device()\n",
        "#     print(\" Device created!\")\n",
        "#     net = net.to(dev)\n",
        "#     print(\"Use TPU\")\n",
        "if use_gpu and torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "    print(\"Use GPU\")\n",
        "else:\n",
        "    print(\"Use CPU\")\n",
        "print(100*'-')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = timeit.default_timer()\n",
        "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
        "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        # if use_tpu and tpu_existed:\n",
        "        #     images = images.to(dev)\n",
        "        #     labels = labels.to(dev)\n",
        "        if use_gpu and torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data))\n",
        "    runtime = timeit.default_timer() - start\n",
        "    print(\"Epoch Runtime: \", runtime)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Use GPU\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [1/5], Step [100/600], Loss: 0.5069\n",
            "Epoch [1/5], Step [200/600], Loss: 0.3709\n",
            "Epoch [1/5], Step [300/600], Loss: 0.2546\n",
            "Epoch [1/5], Step [400/600], Loss: 0.2411\n",
            "Epoch [1/5], Step [500/600], Loss: 0.0745\n",
            "Epoch [1/5], Step [600/600], Loss: 0.1457\n",
            "Epoch Runtime:  7.717695975999959\n",
            "Epoch [2/5], Step [100/600], Loss: 0.1001\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0940\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0936\n",
            "Epoch [2/5], Step [400/600], Loss: 0.1156\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0560\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0754\n",
            "Epoch Runtime:  7.4145907609999995\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0613\n",
            "Epoch [3/5], Step [200/600], Loss: 0.1479\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0356\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0603\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0336\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0215\n",
            "Epoch Runtime:  7.345578411999895\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0207\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0877\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0510\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0384\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0320\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0889\n",
            "Epoch Runtime:  7.554142666999951\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0615\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0234\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0293\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0662\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0286\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0069\n",
            "Epoch Runtime:  7.216666673999953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8xe19rFjz8P",
        "colab_type": "text"
      },
      "source": [
        "#NOT USE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhOeVK6RKz1-",
        "colab_type": "text"
      },
      "source": [
        "## Testing the FNN Model\n",
        "\n",
        "Similar to training the neural network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
        "\n",
        "1. No loss & weights calculation\n",
        "2. No wights update\n",
        "3. Has correct prediction calculation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ue19srtK4C1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0816eee6-aba7-42be-f2b8-7221a8a96bd7"
      },
      "source": [
        "# correct = 0\n",
        "# total = 0\n",
        "# for images, labels in test_loader:\n",
        "#     images = Variable(images.view(-1, 28*28))\n",
        "    \n",
        "#     if use_cuda and torch.cuda.is_available():\n",
        "#         images = images.cuda()\n",
        "#         labels = labels.cuda()\n",
        "    \n",
        "    \n",
        "#     outputs = net(images)\n",
        "#     _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "#     total += labels.size(0)                    # Increment the total count\n",
        "#     correct += (predicted == labels).sum()     # Increment the correct count\n",
        "    \n",
        "# print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10K test images: 97 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7EnBoyK8nR",
        "colab_type": "text"
      },
      "source": [
        "## Save the trained FNN Model for future use\n",
        "\n",
        "We save the trained model as a pickle that can be loaded and used later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uof2bcfIK5n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(net.state_dict(), 'fnn_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usLTAaYZLFml",
        "colab_type": "text"
      },
      "source": [
        "## Congrats\n",
        "\n",
        "You have done building your first Feedforward Neural Network!"
      ]
    }
  ]
}